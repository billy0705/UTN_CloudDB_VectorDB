{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "num_vectors = 10000\n",
    "num_dimensions = 1000\n",
    "random_vectors = np.random.rand(num_vectors, num_dimensions)\n",
    "\n",
    "num_clusters = 3\n",
    "cluster_cen= np.random.rand(num_clusters, num_dimensions)\n",
    "\n",
    "# assign each vector to a cluster and create an arraty for the clustered vectors\n",
    "assign_cluster = np.random.choice(num_clusters, num_vectors)\n",
    "clustered_vectors= np.zeros((num_vectors,num_dimensions))\n",
    "\n",
    "# assign vectors to clusters\n",
    "for i in range(num_clusters):\n",
    "    cluster_index = np.where(assign_cluster == i)[0]\n",
    "    # assign these vectors to cluster centers with some added noice\n",
    "    clustered_vectors[cluster_index] = cluster_cen[i] + np.random.randn(len(cluster_index), num_dimensions) * 0.1\n",
    "\n",
    "np.random.shuffle(clustered_vectors)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(clustered_vectors)\n",
    "\n",
    "df.to_csv('./data/clustered_vectors.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create it for the dataset benchmark\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "\n",
    "num_vectors = 10000\n",
    "num_dimensions = 1000\n",
    "num_test = 2000\n",
    "random_vectors = np.random.rand(num_vectors, num_dimensions)\n",
    "test_vectors = np.random.rand(num_test, num_dimensions)\n",
    "num_clusters = 3\n",
    "cluster_cen= np.random.rand(num_clusters, num_dimensions)\n",
    "\n",
    "# assign each vector to a cluster and create an arraty for the clustered vectors\n",
    "clustered_vectors= np.zeros((num_vectors, num_dimensions))\n",
    "test_clustered_vectors = np.zeros((num_test, num_dimensions))\n",
    "# assign vectors to clusters\n",
    "last = 0\n",
    "last_test = 0\n",
    "for i in range(num_clusters):\n",
    "    sigma = np.random.rand(num_dimensions)*0.5\n",
    "    num_points = int(num_vectors*0.9/num_clusters)\n",
    "    num_test_points = int(num_test*0.9/num_clusters)\n",
    "    clustered_vectors[last:num_points+last,:] = np.random.normal(cluster_cen[i], sigma, size=(num_points, num_dimensions))\n",
    "    test_clustered_vectors[last_test:num_test_points+last_test,:] = np.random.normal(cluster_cen[i], sigma, size=(num_test_points, num_dimensions))\n",
    "    last += num_points\n",
    "    last_test += num_test_points\n",
    "clustered_vectors[last:last+num_vectors,:] = np.random.rand(num_vectors-last, num_dimensions)\n",
    "test_clustered_vectors[last_test:last_test+num_test,:] = np.random.rand(num_test-last_test, num_dimensions)\n",
    "# Shuffle the clustered vectors\n",
    "np.random.shuffle(clustered_vectors)\n",
    "np.random.shuffle(test_clustered_vectors)\n",
    "\n",
    "# Create the train and test DataFrames\n",
    "train_vectors = clustered_vectors\n",
    "test_vectors = test_clustered_vectors\n",
    "\n",
    "# Create the train DataFrame\n",
    "train_df = pd.DataFrame({\n",
    "    'id': np.arange(1, len(train_vectors) + 1),\n",
    "    'emb': train_vectors.tolist()\n",
    "})\n",
    "\n",
    "# Create the test DataFrame\n",
    "test_df = pd.DataFrame({\n",
    "    'id': np.arange(1, len(test_vectors) + 1),\n",
    "    'emb': test_vectors.tolist()\n",
    "})\n",
    "\n",
    "\n",
    "# Define the folder path\n",
    "folder_path = './data'\n",
    "train_df.to_csv(f'{folder_path}/train.csv', index=False, header=False)\n",
    "# Save the DataFrames to Parquet files\n",
    "train_table = pa.Table.from_pandas(train_df)\n",
    "test_table = pa.Table.from_pandas(test_df)\n",
    "\n",
    "pq.write_table(train_table, f'{folder_path}/train.parquet')\n",
    "pq.write_table(test_table, f'{folder_path}/test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
