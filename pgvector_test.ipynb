{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pgvector.psycopg import register_vector\n",
    "\n",
    "table_name = 'vector_test'\n",
    "\n",
    "# test_csv_path = \"./data/similarity_vectors.csv\"\n",
    "# df = pd.read_csv(test_csv_path)\n",
    "# df = df.to_numpy().flatten()\n",
    "# print(df.shape)\n",
    "\n",
    "#establishing the connection\n",
    "with psycopg.connect(\"dbname=postgres user=billyslim password=''\") as conn:\n",
    "    register_vector(conn)\n",
    "    # sim_query = \"\"\"\n",
    "    # SELECT id, embedding <-> (%s) AS distance\n",
    "    # FROM vector_test \n",
    "    # ORDER BY distance ASC\n",
    "    # LIMIT 5;\n",
    "    # \"\"\"\n",
    "\n",
    "    \n",
    "    # result = conn.execute(sim_query, (df,)).fetchall()\n",
    "    \n",
    "    # conn.execute('CREATE EXTENSION IF NOT EXISTS vector')\n",
    "    # conn.execute(f'CREATE TABLE {table_name} (id bigserial PRIMARY KEY, embedding vector(10000))')\n",
    "    index_query = f\"CREATE INDEX ON {table_name} USING hnsw (embedding vector_l2_ops);\"\n",
    "    conn.execute(index_query)\n",
    "    # conn.execute('DROP TABLE vector_index')\n",
    "    # embedding = np.array([1, 2, 3])\n",
    "    # conn.execute('INSERT INTO vector_test (embedding) VALUES (%s)', (embedding,))\n",
    "    # result = conn.execute('SELECT embedding FROM vector_test ORDER BY embedding <-> %s LIMIT 5', (embedding,)).fetchall()\n",
    "    # SELECT pg_size_pretty( pg_total_relation_size('vector_test')); size of table\n",
    "    # print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "138158080\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/pgvector/pgvector-python\n",
    "# https://github.com/pgvector/pgvector\n",
    "\n",
    "from pgvector_interface import PGvectorInterface\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "csv_path = \"./data/clustered_vectors.csv\"\n",
    "table_name = 'vector_test'\n",
    "test_csv_path = \"./data/similarity_vectors.csv\"\n",
    "embedding = pd.read_csv(test_csv_path)\n",
    "embedding = embedding.to_numpy().flatten()\n",
    "r = 0\n",
    "\n",
    "pgvectordb = PGvectorInterface('postgres', 'billyslim')\n",
    "# pgvectordb.create_table(table_name, 1000)\n",
    "pgvectordb.drop_table(table_name)\n",
    "pgvectordb.create_table(table_name, 1000, metrix=\"l2\", index_types=\"hnsw\")\n",
    "# pgvectordb.drop_table(table_name)\n",
    "r = pgvectordb.get_size_of_table(table_name)\n",
    "# embedding = np.array([1, 2, 3])\n",
    "# pgvectordb.insert_single_vector(table_name, embedding)\n",
    "pgvectordb.insert_vector_from_csv(table_name, csv_path)\n",
    "r = pgvectordb.get_rows_cnt(table_name)\n",
    "print(r)\n",
    "r = pgvectordb.get_size_of_table(table_name)\n",
    "# for i in range(10000):\n",
    "#     embedding = np.random.rand(1000)\n",
    "#     r = pgvectordb.similarity_search(table_name, embedding, \"l2\")\n",
    "# r = pgvectordb.similarity_search(table_name, embedding, \"cosine\")\n",
    "# r=pgvectordb.get_rows_cnt(table_name)\n",
    "pgvectordb.disconnect_server()\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    [\n",
      "        {\n",
      "            \"id\": 7932,\n",
      "            \"distance\": 0.7603577971458435,\n",
      "            \"entity\": {}\n",
      "        }\n",
      "    ]\n",
      "]\n",
      "{'row_count': 10000}\n",
      "['vector_test2']\n"
     ]
    }
   ],
   "source": [
    "# Milvus\n",
    "# pip install pymilvus milvus\n",
    "# https://github.com/ytang07/milvus-projects/blob/main/text/embedding_comparison.ipynb\n",
    "# https://milvus.io/docs/manage_databases.md\n",
    "from pymilvus import connections, utility, FieldSchema, CollectionSchema, DataType, Collection, db\n",
    "# conn = connections.connect(host=\"127.0.0.1\", port=19530)\n",
    "from pymilvus import MilvusClient\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "name = \"vector_test2\"\n",
    "csv_path = \"./data/clustered_vectors.csv\"\n",
    "\n",
    "test_csv_path = \"./data/similarity_vectors.csv\"\n",
    "embedding = pd.read_csv(test_csv_path)\n",
    "embedding = embedding.to_numpy().flatten()\n",
    "\n",
    "client = MilvusClient(\"milvus_db/milvus_demo.db\")\n",
    "\n",
    "# client.drop_collection(\n",
    "#     collection_name=name\n",
    "# )\n",
    "\n",
    "# if client.has_collection(name):\n",
    "#     res = client.describe_collection(\n",
    "#         collection_name=name\n",
    "#     )\n",
    "#     print(res)\n",
    "# else:\n",
    "#     client.create_collection(\n",
    "#         collection_name=name,\n",
    "#         dimension=1000\n",
    "#     )\n",
    "\n",
    "# df = pd.read_csv(csv_path)\n",
    "# df = df.to_numpy()\n",
    "# print(f\"{df.shape = }\")\n",
    "# data = [\n",
    "#     {\"id\": i, \"vector\": df[i, :]}\n",
    "#     for i in range(df.shape[0])\n",
    "# ]\n",
    "# print(len(data))\n",
    "\n",
    "# res = client.insert(\n",
    "#     collection_name=name,\n",
    "#     data=data\n",
    "# )\n",
    "\n",
    "# print(res)\n",
    "\n",
    "res = client.search(\n",
    "    collection_name=name, # Replace with the actual name of your collection\n",
    "    # Replace with your query vector\n",
    "    data=[embedding.tolist()],\n",
    "    limit=1, # Max. number of search results to return\n",
    "    search_params={\"metric_type\": \"COSINE\", \"params\": {}} # Search parameters\n",
    ")\n",
    "\n",
    "# Convert the output to a formatted JSON string\n",
    "result = json.dumps(res, indent=4)\n",
    "print(result)\n",
    "\n",
    "\n",
    "\n",
    "# collection = client.load_collection(\n",
    "#     collection_name=name\n",
    "# )\n",
    "\n",
    "res = client.get_collection_stats(\n",
    "    collection_name=name\n",
    ")\n",
    "\n",
    "print(res)\n",
    "\n",
    "res = client.list_collections()\n",
    "print(res)\n",
    "\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
