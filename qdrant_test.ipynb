{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhimi\\AppData\\Local\\Temp\\ipykernel_35628\\2033497685.py:11: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  qdrant.recreate_collection(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import PointStruct\n",
    "import pandas as pd\n",
    "from qdrant_interface import QDrantInterface\n",
    "\n",
    "\n",
    "clustered_vectors = pd.read_csv('./data/clustered_vectors.csv').values\n",
    "\n",
    "qdrant = QdrantClient(\":memory:\")\n",
    "collection_name = \"vector_collection\"\n",
    "\n",
    "qdrant.recreate_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config={\"size\": clustered_vectors.shape[1], \"distance\": \"Cosine\"}\n",
    ")\n",
    "\n",
    "# Upload the vectors\n",
    "points = [\n",
    "    PointStruct(id=i, vector=vector.tolist())\n",
    "    for i, vector in enumerate(clustered_vectors)\n",
    "]\n",
    "\n",
    "qdrant.upsert(collection_name=collection_name, points=points)\n",
    "\n",
    "# source https://python-client.qdrant.tech/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=0 version=0 score=0.9999999988241883 payload={} vector=None shard_key=None order_value=None\n",
      "id=4791 version=0 score=0.9733456684059761 payload={} vector=None shard_key=None order_value=None\n",
      "id=112 version=0 score=0.9731442626214278 payload={} vector=None shard_key=None order_value=None\n",
      "id=596 version=0 score=0.9729512723259301 payload={} vector=None shard_key=None order_value=None\n",
      "id=4477 version=0 score=0.97288293892145 payload={} vector=None shard_key=None order_value=None\n",
      "id=6595 version=0 score=0.9728680538292809 payload={} vector=None shard_key=None order_value=None\n",
      "id=4060 version=0 score=0.9728547648246987 payload={} vector=None shard_key=None order_value=None\n",
      "id=9043 version=0 score=0.9728345841123753 payload={} vector=None shard_key=None order_value=None\n",
      "id=1091 version=0 score=0.9728207069369069 payload={} vector=None shard_key=None order_value=None\n",
      "id=2757 version=0 score=0.9727718166003076 payload={} vector=None shard_key=None order_value=None\n"
     ]
    }
   ],
   "source": [
    "# doing a search query test\n",
    "query_vector = clustered_vectors[0].tolist()\n",
    "\n",
    "search_result = qdrant.search(\n",
    "    collection_name=collection_name,\n",
    "    query_vector=query_vector,\n",
    "    limit=10 \n",
    ")\n",
    "\n",
    "# Print the search results\n",
    "for result in search_result:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vector dataset size: 193002578 bytes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "csv_file_path = './data/clustered_vectors.csv'\n",
    "org_size = os.path.getsize(csv_file_path)\n",
    "\n",
    "print(f\"Original vector dataset size: {org_size} bytes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhimi\\AppData\\Local\\Temp\\ipykernel_35628\\1281254356.py:13: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  qdrant.recreate_collection(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated size of data in Qdrant: 40000000 bytes\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import PointStruct\n",
    "import pandas as pd\n",
    "\n",
    "# Init qdrant client like the test before\n",
    "\n",
    "clustered_vectors = pd.read_csv('./data/clustered_vectors.csv').values\n",
    "\n",
    "qdrant = QdrantClient(\":memory:\")\n",
    "collection_name = \"vector_collection\"\n",
    "\n",
    "qdrant.recreate_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config={\"size\": clustered_vectors.shape[1], \"distance\": \"Cosine\"}\n",
    ")\n",
    "\n",
    "# Upload the vectors\n",
    "points = [\n",
    "    PointStruct(id=i, vector=vector.tolist())\n",
    "    for i, vector in enumerate(clustered_vectors)\n",
    "]\n",
    "\n",
    "qdrant.upsert(collection_name=collection_name, points=points)\n",
    "#*******************************************************************************\n",
    "# do an einitial estimation of the size per vector\n",
    "size_per_vector = clustered_vectors.shape[1] * 4  # Each float is 4 bytes\n",
    "\n",
    "num_vectors = clustered_vectors.shape[0]\n",
    "\n",
    "# an stimation of the total storage size\n",
    "estimated_qdrant_size = size_per_vector * num_vectors\n",
    "\n",
    "print(f\"Estimated size of data in Qdrant: {estimated_qdrant_size} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vector dataset size: 193002578 bytes\n",
      "Estimated size of data in Qdrant: 40000000 bytes\n",
      "Compression ratio (original/Qdrant): 4.83\n"
     ]
    }
   ],
   "source": [
    "org_size = os.path.getsize(csv_file_path)\n",
    "\n",
    "print(f\"Original size: {org_size} bytes\")\n",
    "print(f\"Estimated size  in Qdrant: {estimated_qdrant_size} bytes\")\n",
    "\n",
    "compression_ratio = org_size / estimated_qdrant_size\n",
    "print(f\"Compression ratio (original/Qdrant): {compression_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of data in Qdrant: 95928320 bytes\n",
      "Original vector dataset size: 192957645 bytes\n",
      "Compression ratio (original/Qdrant): 2.01\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance, PointStruct\n",
    "\n",
    "clustered_vectors = pd.read_csv('./data/clustered_vectors.csv').values\n",
    "qdrant = QdrantClient(path=\"./qdrant_data\")\n",
    "collection_name = \"vector_collection\"\n",
    "qdrant.create_collection(\n",
    "   collection_name=collection_name,\n",
    "   vectors_config=VectorParams(size=clustered_vectors.shape[1], distance=Distance.COSINE),\n",
    ")\n",
    "points = [\n",
    "    PointStruct(id=i, vector=vector.tolist())\n",
    "    for i, vector in enumerate(clustered_vectors)\n",
    "]\n",
    "\n",
    "qdrant.upsert(collection_name=collection_name, points=points)\n",
    "# *****************************************************\n",
    "\n",
    "def get_directory_size(directory):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(directory):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            total_size += os.path.getsize(fp)\n",
    "    return total_size\n",
    "\n",
    "# Getting thr qdrant data directory size\n",
    "qdrant_data_size = get_directory_size('./qdrant_data/collection/vector_collection')\n",
    "print(f\"Size of data in Qdrant: {qdrant_data_size} bytes\")\n",
    "\n",
    "original_size = os.path.getsize('./data/clustered_vectors.csv')\n",
    "print(f\"Original vector dataset size: {original_size} bytes\")\n",
    "\n",
    "# Calculate the compression ratio\n",
    "compression_ratio = original_size / qdrant_data_size\n",
    "print(f\"Compression ratio (original/Qdrant): {compression_ratio:.2f}\")\n",
    "\n",
    "#https://www.slingacademy.com/article/python-calculating-total-size-of-a-folder-and-its-contents/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status=<CollectionStatus.GREEN: 'green'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=None indexed_vectors_count=0 points_count=10000 segments_count=1 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=1000, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None, datatype=None, multivector_config=None), shard_number=None, sharding_method=None, replication_factor=None, write_consistency_factor=None, read_fan_out_factor=None, on_disk_payload=None, sparse_vectors=None), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=None, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=None, indexing_threshold=20000, flush_interval_sec=5, max_optimization_threads=1), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=None) payload_schema={}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "collection_name = \"vector_collection\"\n",
    "r = qdrant.get_collection(collection_name)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<tokenize>:10\u001b[1;36m\u001b[0m\n\u001b[1;33m    def get_rows_cnt(self, table_name):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "# to be done\n",
    "\n",
    "\n",
    "\n",
    "    def get_rows_cnt(self, table_name):\n",
    "        query = f'SELECT COUNT(*) FROM {table_name}'\n",
    "        result = self.conn.execute(query).fetchall()\n",
    "        # print(result)\n",
    "        self.conn.commit()\n",
    "        return result[0][0]\n",
    "\n",
    "    def similarity_search(self, table_name, embedding_vector, metrix):\n",
    "        if metrix == \"l2\":\n",
    "            symbol = \"<->\"\n",
    "        elif metrix == \"cosine\":\n",
    "            symbol = \"<=>\"\n",
    "        else:\n",
    "            print(\"Error with matrix type\")\n",
    "            return\n",
    "        sim_query = f\"\"\"\n",
    "        SELECT id, embedding {symbol} (%s) AS distance\n",
    "        FROM {table_name}\n",
    "        ORDER BY distance ASC\n",
    "        LIMIT 5\n",
    "        \"\"\"\n",
    "        result = self.conn.execute(sim_query, (embedding_vector,)).fetchall()\n",
    "        # print(result)\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for insert single vector\n",
    "qdrant_interface = QDrantInterface(data_path='./qdrant_data')\n",
    "print(\"Connected to Qdrant server.\")\n",
    "\n",
    "qdrant_interface.drop_table('vector_collection')\n",
    "\n",
    "qdrant_interface.create_table(collection_name='vector_collection', vector_size=5)\n",
    "print(\"Collection created successfully.\")\n",
    "\n",
    "# Insert a single vector\n",
    "try:\n",
    "    sample_vector = np.array([0.1, 0.2, 0.3, 0.4, 0.5])\n",
    "    qdrant_interface.insert_single_vector(collection_name='vector_collection', vector=sample_vector)\n",
    "    print(\"Vector inserted successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while inserting the vector: {e}\")\n",
    "\n",
    "qdrant_interface.disconnect_server()\n",
    "print(\"Disconnected from Qdrant server.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Qdrant server.\n",
      "Collection created successfully.\n",
      "Vectors inserted successfully from CSV.\n",
      "An error occurred while getting the row count: 'CollectionInfo' object is not subscriptable\n",
      "Similarity search result: [{'id': 8484, 'score': 0.7967769209702504}, {'id': 6689, 'score': 0.7963385296990608}, {'id': 1685, 'score': 0.7961955815548707}, {'id': 170, 'score': 0.7957872332440298}, {'id': 503, 'score': 0.7956461530576955}]\n",
      "Disconnected from Qdrant server.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import PointStruct\n",
    "import pandas as pd\n",
    "from qdrant_interface import QDrantInterface\n",
    "\n",
    "# testing\n",
    "qdrant_interface = QDrantInterface(data_path='./qdrant_data')\n",
    "print(\"Connected to Qdrant server.\")\n",
    "\n",
    "qdrant_interface.drop_table('vector_collection')\n",
    "\n",
    "qdrant_interface.create_table(collection_name='vector_collection', vector_size=1000)\n",
    "print(\"Collection created successfully.\")\n",
    "\n",
    "# # Insert a single vector\n",
    "# try:\n",
    "#     sample_vector = np.array([0.1, 0.2, 0.3, 0.4, 0.5])\n",
    "#     qdrant_interface.insert_single_vector(collection_name='vector_collection', vector=sample_vector)\n",
    "#     print(\"Vector inserted successfully.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"An error occurred while inserting the vector: {e}\")\n",
    "\n",
    "# Insert vectors from CSV\n",
    "try:\n",
    "    points = qdrant_interface.transfer_csv('./data/clustered_vectors.csv')\n",
    "    qdrant_interface.insert_vector_from_csv(collection_name='vector_collection', points=points)\n",
    "    print(\"Vectors inserted successfully from CSV.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while inserting vectors from CSV: {e}\")\n",
    "\n",
    "# Get row count\n",
    "try:\n",
    "    rows_count = qdrant_interface.get_rows_cnt(collection_name='vector_collection')\n",
    "    print(f\"Number of vectors in the collection: {rows_count}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while getting the row count: {e}\")\n",
    "\n",
    "try:\n",
    "    sample_vector = [0.1, 0.2, 0.3, 0.4, 0.5] * 200  # Adjusted to match 1000 dimensions\n",
    "    search_result = qdrant_interface.similarity_search(collection_name='vector_collection', embedding_vector=sample_vector, metric='cosine', limit=5)\n",
    "    print(f\"Similarity search result: {search_result}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during similarity search: {e}\")\n",
    "\n",
    "qdrant_interface.disconnect_server()\n",
    "print(\"Disconnected from Qdrant server.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Qdrant server.\n",
      "Collection created successfully.\n",
      "Vectors inserted successfully from CSV.\n",
      "status=<CollectionStatus.GREEN: 'green'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=None indexed_vectors_count=0 points_count=10000 segments_count=1 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=1000, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None, datatype=None, multivector_config=None), shard_number=None, sharding_method=None, replication_factor=None, write_consistency_factor=None, read_fan_out_factor=None, on_disk_payload=None, sparse_vectors=None), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=None, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=None, indexing_threshold=20000, flush_interval_sec=5, max_optimization_threads=1), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=None) payload_schema={}\n",
      "Number of vectors in the collection: 10000\n",
      "Disconnected from Qdrant server.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import PointStruct\n",
    "import pandas as pd\n",
    "from qdrant_interface import QDrantInterface\n",
    "\n",
    "# testing\n",
    "qdrant_interface = QDrantInterface(data_path='./qdrant_data')\n",
    "print(\"Connected to Qdrant server.\")\n",
    "\n",
    "qdrant_interface.drop_table('vector_collection')\n",
    "\n",
    "qdrant_interface.create_table(collection_name='vector_collection', vector_size=1000, index_types=\"Hnsw\")\n",
    "print(\"Collection created successfully.\")\n",
    "\n",
    "# # Insert a single vector\n",
    "# try:\n",
    "#     sample_vector = np.array([0.1, 0.2, 0.3, 0.4, 0.5])\n",
    "#     qdrant_interface.insert_single_vector(collection_name='vector_collection', vector=sample_vector)\n",
    "#     print(\"Vector inserted successfully.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"An error occurred while inserting the vector: {e}\")\n",
    "\n",
    "# Insert vectors from CSV\n",
    "try:\n",
    "    points = qdrant_interface.transfer_csv('./data/clustered_vectors.csv')\n",
    "    qdrant_interface.insert_vector_from_csv(collection_name='vector_collection', points=points)\n",
    "    print(\"Vectors inserted successfully from CSV.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while inserting vectors from CSV: {e}\")\n",
    "\n",
    "# Get row count\n",
    "try:\n",
    "    rows_count = qdrant_interface.get_rows_cnt(collection_name='vector_collection')\n",
    "    print(f\"Number of vectors in the collection: {rows_count}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while getting the row count: {e}\")\n",
    "\n",
    "# try:\n",
    "#     sample_vector = [0.1, 0.2, 0.3, 0.4, 0.5]   # Adjusted to match 1000 dimensions\n",
    "#     search_result = qdrant_interface.similarity_search(collection_name='vector_collection', embedding_vector=sample_vector, metric='cosine', limit=5)\n",
    "#     print(f\"Similarity search result: {search_result}\")\n",
    "# except Exception as e:\n",
    "#     print(f\"An error occurred during similarity search: {e}\")\n",
    "\n",
    "qdrant_interface.disconnect_server()\n",
    "print(\"Disconnected from Qdrant server.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
